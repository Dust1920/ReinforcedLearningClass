[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ReinforcedLearningClass",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\\[\nx^2 + 10 = 100\n\\tag{1}\\]\nPrueba Ecuación 1\nReferencia ejemplo Ayers (2005) Referencia ejemplo (see Ayers 2005, 52-53; B. Thomas Jr 2010, cap. 1)\nBlack-Scholes (Ecuación 2) is a mathematical model that seeks to explain the behavior of financial derivatives, most commonly options:\n\\[\n\\frac{\\partial \\mathrm C}{ \\partial \\mathrm t } + \\frac{1}{2}\\sigma^{2} \\mathrm S^{2}\n\\frac{\\partial^{2} \\mathrm C}{\\partial \\mathrm C^2}\n  + \\mathrm r \\mathrm S \\frac{\\partial \\mathrm C}{\\partial \\mathrm S}\\ =\n  \\mathrm r \\mathrm C\n\\tag{2}\\]\n\n\n\n\nAyers, G. 2005. «Air Pollution and Climate Change: Has Air Pollution Suppressed Rainfall over Australia?» 39 (2): 51-57. https://search.informit.org/doi/10.3316/informit.632702153657460.\n\n\nB. Thomas Jr, George. 2010. Cálculo varias variables. Doceava. Addison-Wesley."
  },
  {
    "objectID": "Tarea1.html",
    "href": "Tarea1.html",
    "title": "1  Tarea 1 (Fecha de Entrega 20 Septiembre 2024 12:00:00)",
    "section": "",
    "text": "Exercise 1.1 Read (Sec 1.1, pp 1-2 Sutton and Barto 2018) and answer the following. Explain why Reinforcement Learning differs for supervised and unsupervised.\n\n\nEl aprendizaje supervisado requiere de ejemplos de soluciones. Mientras que el reforzado requiere una función de valor.\n\n\nExercise 1.2 See the first Brunton’s youtube about Reinforced Learning. Then acordingly to its presentation explain what is the meaning of the following expression.\n\\[\nV_\\pi(s) = E\\left(\\sum_t\\gamma^tr_t\\mid s_0=s\\right)\n\\]\n\n\nLa expresión presentada en el video Reinforcement Learning. \\[\nV_\\pi (s) = E\\left[\\left. \\sum_{t}\\gamma^t r_t \\right| s_0 = s\\right]\n\\]\nhace referencia a la función de valor del problema de optimización representada por la recompensa esperada dado la politica \\(\\pi\\) y el estado inicial \\(s\\). Aquí \\(\\gamma\\) es el factor de descuento y \\(r_t\\) es la recompensa por etapa \\(t\\).\n\n\nExercise 1.3 Form (see Sutton and Barto 2018, sec. 1.7) obtain a time line pear year from 1950 to 2012.\n\n\nlibrary(devtools)\n\nWarning: package 'devtools' was built under R version 4.3.3\n\n\nLoading required package: usethis\n\n\nWarning: package 'usethis' was built under R version 4.3.3\n\nlibrary(milestones)\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'tibble' was built under R version 4.3.3\n\n\nWarning: package 'tidyr' was built under R version 4.3.3\n\n\nWarning: package 'readr' was built under R version 4.3.3\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\nWarning: package 'forcats' was built under R version 4.3.3\n\n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\n\nWarning: package 'gt' was built under R version 4.3.3\n\n#library(bibtex)\n## Activate the Core Packages\n#biblio &lt;- bibtex::read.bib(\"references.bib\")\n\n## Initialize defaults\ncolumn &lt;- lolli_styles()\n\ndata &lt;- read_csv(col_names=TRUE, show_col_types=FALSE, file='rl_time_line.csv')\n\n\ndata &lt;- data |&gt; arrange(date)\n\n## Build a table\ngt(data) |&gt;\n  #cols_hide(columns = event) |&gt;\n  tab_style(cell_text(v_align = \"top\"),\n            locations = cells_body(columns = date)) |&gt;\n  tab_source_note(source_note = \"Source: Sutton and Barto (2018)\") \n\n\n\n\n\n  \n    \n      date\n      event\n      reference\n    \n  \n  \n    1911\nThe Law Effect\nThorndike, 1911\n    1950\n\"optimal control\" term\nMR0090477 Bellman, Richard Dynamic programming. Princeton University Press, Princeton, NJ, 1957. xxv+342 pp.\n    1954\nTrial and Error Learning\nMinsky,Farley, Clark 1954\n    1957\nDynamic Programming\nMR0090477 Bellman, Richard Dynamic programming. Princeton University Press, Princeton, NJ, 1957. xxv+342 pp.\n    1957\nMarkovian Decision Processes\nMR0091859 Bellman, Richard A Markovian decision process.J. Math. Mech.6(1957), 679-684.\n    1960\nPolicy iteration method\nRon Howard (1960)\n    1960\n\"Reinforcement\" and \"R. Learning\" terms\nNA\n    1960\nLearning with a critic\nHoff, 1960\n    1961\nSteps Toward Artificial Inteligence\nMinsky, 1961\n    1963\nTic Tac Toe\nDonald Michie, 1961\n    1968\nGLEE and BOXES\nMichie and Chambers 1968\n    1982\nAsynchronous methods\nBertsekas, 1982\n    1982\nModern Dynamic Programming\nWhite 1982\n    1983\nAsynchronous methods\nMR0712113 Bertsekas, Dimitri P. Distributed asynchronous computation of fixed points.Math. Programming27(1983), no.1, 107-120.\n    1983\nModern Dynamic Programming\nMR0749232 Ross, Sheldon Introduction to stochastic dynamic programming. Probab. Math. Statist. Academic Press, Inc. [Harcourt Brace Jovanovich, Publishers], New York, 1983. xi+164 pp. ISBN:0-12-598420-0\n    1983\nModern Dynamic Programming\nWhite 1983\n    1985\nMany Aplications\nMR1295629 White, D. J. Markov decision processes.John Wiley & Sons, Ltd., Chichester, 1993. xiv+224 pp. ISBN:0-471-93627-8\n    1988\nMany Aplications\nMR1295629 White, D. J. Markov decision processes.John Wiley & Sons, Ltd., Chichester, 1993. xiv+224 pp. ISBN:0-471-93627-8\n    1991\nPartially Observable MDPs\nMR1105166 Lovejoy, William S.A survey of algorithmic methods for partially observed Markov decision processes.Ann. Oper. Res.28(1991), no.1-4, 47-65\n    1993\nMany Aplications\nMR1200993 White, D. J.Markov decision processes: discounted expected reward or average expected reward?.J. Math. Anal. Appl.172(1993), no.2, 375-384.\n    1994\nModern Dynamic Programming\nPuterman, 1994\n    1995\nModern Dynamic Programming\nBertsekas, 1995\n    1996\nAproximathon methods\nMR1416619 Rust, John Numerical dynamic programming in economics.Handbook of computational economics, Vol. I, 619-729. Handbooks in Econom., 13 North-Holland Publishing Co., Amsterdam, 1996 ISBN:0-444-89857-3\n  \n  \n    \n      Source: Sutton and Barto (2018)\n    \n  \n  \n\n\n\ncolumn$color &lt;- \"orange\"\ncolumn$size  &lt;- 15\ncolumn$source_info &lt;- \"Source: Sutton and Barto (2018)\"\n\n## Milestones timeline\nmilestones(datatable = data, styles = column)\n\n\n\n\n\nExercise 1.4 Consider the following comsuption-saving problem with dynamics \\[\nx_{k+1} = (1+r)(x_k-a_k), k = 0,1,\\ldots,N-1\n\\]\nand utility function\n\\[\n\\beta^N(x_N)^{1-\\gamma} + \\sum_{k=0}^{N-1}\\beta^k(a_k)^{1-\\gamma}.\n\\]\nShow that the value functions of the DP alghorithm the form\n\\[\nJ_k(x) = A_kk\\beta^k x^{1-\\gamma},\n\\]\nwhere \\(A_N=1\\) and for \\(k=N-1,\\ldots,0\\),\n\\[\nA_k = \\left[1 + \\left((1+r)\\beta A_{k+1}\\right)^{1/\\gamma}\\right]^\\gamma.\n\\]\nShow also that the optimal policies are \\(h_k(x) = A^{-1/\\gamma}x\\), for \\(k = N-1,\\ldots,0\\).\n\n\n\nConsiderando \\(J_{N}\\) como sigue\n\\[\nJ_{N}\\left(x\\right)=\\beta^{N}x^{1-\\gamma}K_{N},\n\\]\ncon \\(K_{N}=1\\) bajo la hipótesis de que \\[\nc_{k}\\left(x,a\\right)=\\beta^{k}a^{1-\\gamma}\n\\] calculamos \\(J_{N-1}\\).\n\\[\\begin{align*}\nJ_{N-1}\\left(x\\right) & =\\max_{a\\in A\\left(x\\right)}\\left\\{ c_{N-1}(x,a)+J_{N}\\left((1+i)(x-a)\\right)\\right\\} \\\\\n& =\\max_{a\\in A\\left(x\\right)}\\left\\{ \\beta^{N-1}a^{1-\\gamma}+\\beta^{N}\\left((1+i)(x-a)\\right)^{1-\\gamma}\\right\\}\n\\end{align*}\\]\nDefinimos el argumento como una función \\(q\\).\n\\[\\begin{align*}\nq(x,a) & =\\beta^{N-1}a^{1-\\gamma}+\\beta^{N}\\left((1+i)(x-a)\\right)^{1-\\gamma}\\\\\n& =C_{1}a^{1-\\gamma}+C_{2}\\left(x-a\\right)^{1-\\gamma},\n\\end{align*}\\]\ndonde \\(C_{1}=\\beta^{N-1}\\) y \\(C_{2}=\\beta^{N}(1+i)^{1-\\gamma}K_{N}.\\) Como \\(q\\) es continua en \\(\\left(x,a\\right)\\). Podemos calcular el máximo mediante el gradiente.\n\\[\n\\partial_{a}q=C_{1}\\left(1-\\gamma\\right)a^{-\\gamma}-C_{2}(1-\\gamma)\\left(x-a\\right)^{-\\gamma}.\n\\]\nIgualando, \\(\\partial_{a}q=0\\). \\[\\begin{align*}\nC_{1}a^{-\\gamma} & =C_{2}\\left(x-a\\right)^{-\\gamma}\\\\\n\\dfrac{C_{1}}{C_{2}} & =\\left(\\dfrac{x-a}{a}\\right)^{-\\gamma}\\\\\n\\left(\\dfrac{C_{1}}{C_{2}}\\right)^{-\\frac{1}{\\gamma}} & =\\frac{x}{a}-1\\\\\n\\left(\\dfrac{C_{1}}{C_{2}}\\right)^{-\\frac{1}{\\gamma}}+1 & =\\frac{x}{a}\\\\\na & =\\dfrac{x}{\\left(\\dfrac{C_{1}}{C_{2}}\\right)^{-\\frac{1}{\\gamma}}+1}\n\\end{align*}\\]\nFinalmente \\[\na=h(x)=\\dfrac{x}{\\left(\\beta(1+i)^{1-\\gamma}\\right)^{\\frac{1}{\\gamma}}+1}\n\\]\nDefiniendo \\(\\eta=\\left(\\beta(1+i)^{1-\\gamma}\\right)^{\\frac{1}{\\gamma}}+1,\\) \\(\\eta-1=\\left(\\beta(1+i)^{1-\\gamma}\\right)^{\\frac{1}{\\gamma}}\\)\nentonces \\[\nh(x)=\\dfrac{x}{\\eta},\n\\]\n\\[\\begin{align*}\nJ_{N-1}(x) & =\\beta^{N-1}\\left(\\dfrac{x}{\\eta}\\right)^{1-\\gamma}+\\beta^{N}\\left((1+i)\\left(x-\\dfrac{x}{\\eta}\\right)\\right)^{1-\\gamma}\\\\\n& =\\beta^{N-1}x^{1-\\gamma}\\left(\\eta^{\\gamma-1}+\\beta\\left(1+i\\right)^{1-\\gamma}\\left(\\dfrac{\\eta-1}{\\eta}\\right)^{1-\\gamma}\\right)\\\\\n& =\\beta^{N-1}x^{1-\\gamma}\\eta^{\\gamma-1}\\left(1+\\beta\\left(1+i\\right)^{1-\\gamma}\\left(\\eta-1\\right)^{1-\\gamma}\\right)\\\\\n& =\\beta^{N-1}x^{1-\\gamma}\\eta^{\\gamma-1}\\left(1+\\beta\\left(1+i\\right)^{1-\\gamma}\\left(\\eta-1\\right)^{1-\\gamma}\\right)\\\\\n& =\\beta^{N-1}x^{1-\\gamma}\\eta^{\\gamma-1}\\left(1+\\beta\\left(1+i\\right)^{1-\\gamma}\\left(\\left(\\beta(1+i)^{1-\\gamma}\\right)^{\\frac{1}{\\gamma}}\\right)^{1-\\gamma}\\right)\\\\\n& =\\beta^{N-1}x^{1-\\gamma}\\eta^{\\gamma-1}\\left(1+\\beta\\left(1+i\\right)^{1-\\gamma}\\left(\\beta(1+i)^{1-\\gamma}\\right)^{\\frac{1}{\\gamma}-1}\\right)\\\\\n& =\\beta^{N-1}x^{1-\\gamma}\\eta^{\\gamma-1}\\left(1+\\beta^{\\frac{1}{\\gamma}}(1+i)^{\\left(1-\\gamma\\right)\\left(\\frac{1}{\\gamma}-1\\right)+1-\\gamma}\\right)\\\\\n& =\\beta^{N-1}x^{1-\\gamma}\\eta^{\\gamma-1}\\left(1+\\beta^{\\frac{1}{\\gamma}}(1+i)^{\\left(\\frac{1}{\\gamma}-1\\right)}\\right)\\\\\n& =\\beta^{N-1}x^{1-\\gamma}\\eta^{\\gamma},\n\\end{align*}\\]\nEntonces \\[\nK_{N-1}=\\eta^{\\gamma},h_{k-1}\\left(x\\right)=\\dfrac{x}{\\left(K_{N-1}\\right)^{1/\\gamma}}\n\\]\nAhora calculamos \\(J_{N-2}\\)\n\\[\\begin{align*}\nJ_{N-2}\\left(x\\right) & =\\max_{a\\in A\\left(x\\right)}\\left\\{ \\beta^{N-2}a^{1-\\gamma}+\\beta^{N-1}\\left[\\left(1+i\\right)\\left(x-a\\right)\\right]^{1-\\gamma}\\eta^{\\gamma}\\right\\} \\\\\n& =\\max_{a\\in A\\left(x\\right)}\\left\\{ q\\left(x,a\\right)\\right\\} ,\n\\end{align*}\\]\ndonde \\[\nq\\left(x,a\\right)=C_{1}a^{1-\\gamma}+C_{2}\\left(x-a\\right)^{1-\\gamma},\n\\]\ncon \\(C_{1}=\\beta^{N-2}\\) y \\(C_{2}=\\beta^{N-1}\\left(1+i\\right)^{1-\\gamma}K_{N-1}\\) . Obteniendo, por recursividad \\[\\begin{align*}\nh_{N-2} & =\\dfrac{x}{\\left(\\dfrac{C_{1}}{C_{2}}\\right)^{-\\frac{1}{\\gamma}}+1}\\\\\n& =\\dfrac{x}{\\left(\\dfrac{1}{\\beta\\left(1+i\\right)^{1-\\gamma}K_{N-1}}\\right)^{-\\frac{1}{\\gamma}}+1}\\\\\n& =\\dfrac{x}{\\left(\\beta\\left(1+i\\right)^{1-\\gamma}K_{N-1}\\right)^{\\frac{1}{\\gamma}}+1}\n\\end{align*}\\]\nEntonces, sea \\[\\begin{align*}\n\\eta' & =\\left(\\beta\\left(1+i\\right)^{1-\\gamma}K_{N-1}\\right)^{\\frac{1}{\\gamma}}+1.\n\\end{align*}\\]\nRepitiendo, el caso anterior, tenemos que \\[\\begin{align*}\nJ_{N-2}\\left(x\\right) & =\\beta^{N-2}x^{1-\\gamma}\\eta_{'}^{\\gamma-1}\\left(1+K_{N-1}\\beta\\left(1+i\\right)^{1-\\gamma}\\left(\\left(\\beta(1+i)^{1-\\gamma}K_{N-1}\\right)^{\\frac{1}{\\gamma}}\\right)^{1-\\gamma}\\right)\\\\\n& =\\beta^{N-2}x^{1-\\gamma}\\eta_{'}^{\\gamma-1}\\left(1+K_{N-1}\\beta\\left(1+i\\right)^{1-\\gamma}\\left(\\left(\\beta(1+i)^{1-\\gamma}K_{N-1}\\right)^{\\frac{1}{\\gamma}}\\right)^{1-\\gamma}\\right)\\\\\n& =\\beta^{N-2}x^{1-\\gamma}\\eta_{'}^{\\gamma-1}\\left(1+K_{N-1}\\beta\\left(1+i\\right)^{1-\\gamma}\\left(\\beta(1+i)^{1-\\gamma}K_{N-1}\\right)^{\\frac{1}{\\gamma}-1}\\right)\\\\\n& =\\beta^{N-2}x^{1-\\gamma}\\eta_{'}^{\\gamma-1}\\left(1+K_{N-1}\\beta\\left(1+i\\right)^{1-\\gamma}(1+i)^{\\left(1-\\gamma\\right)\\left(\\frac{1}{\\gamma}-1\\right)}K_{N-1}^{\\frac{1}{\\gamma}-1}\\right)\\\\\n& =\\beta^{N-2}x^{1-\\gamma}\\eta_{'}^{\\gamma-1}\\left(1+K_{N-1}\\beta^{1/\\gamma}\\left(1+i\\right)^{\\frac{1}{\\gamma}-1}K_{N-1}^{\\frac{1}{\\gamma}-1}\\right)\\\\\n& =\\beta^{N-2}x^{1-\\gamma}\\eta_{'}^{\\gamma-1}\\left(1+\\beta^{1/\\gamma}\\left(1+i\\right)^{\\frac{1}{\\gamma}-1}K_{N-1}^{\\frac{1}{\\gamma}}\\right)\\\\\n& =\\beta^{N-2}x^{1-\\gamma}\\eta'{}^{\\gamma},\n\\end{align*}\\]\nentonces \\[\nK_{N-2}=\\eta'{}^{\\gamma},\n\\]\ny \\[\nh_{N-2}=\\dfrac{x}{K_{N-2}^{1/\\gamma}}\n\\]\nPor lo tanto, tenemos que \\[\nK_{n}=\\left(\\beta\\left(1+i\\right)^{1-\\gamma}K_{n+1}\\right)^{\\frac{1}{\\gamma}}+1,n=0,1,2,\\ldots,N,\n\\] con \\(K_{N}=1\\).\nObteniendo así \\[\\begin{align*}\nJ_{n}\\left(x\\right) & =\\beta^{n}x^{1-\\gamma}K_{n}\\\\\nh_{n}\\left(x\\right) & =\\dfrac{x}{K_{n}^{1/\\gamma}}\n\\end{align*}\\]\n\n\n\nExercise 1.5 Consider now the infinite-horizon version of the above compsumption problem.\n\nWrite down the associated Bellman equation.\nArgue why a solution to the Bellman equation should be the form\n\n\\[\nv(x) = cx^{1-\\gamma},\n\\]\nwhere \\(c\\) is constant. Find the constant \\(c\\) and the stationary optimal policy.\n\n\nPara el caso infinito. Estamos considerando \\[\nc\\left(x,a\\right)=a^{1-\\gamma}\n\\]\nEntonces \\[\n\\nu\\left(x\\right)=\\max_{a\\in A\\left(x\\right)}\\left\\{ a^{1-\\gamma}+\\beta\\nu\\left(\\left(1+i\\right)\\left(x-a\\right)\\right)\\right\\} ,\n\\]\nconsiderando \\(\\nu\\left(x\\right)=cx^{1-\\gamma}.\\) Entonces \\[\n\\nu\\left(x\\right)=\\max_{a\\in A\\left(x\\right)}\\left\\{ a^{1-\\gamma}+\\beta c\\left[\\left(1+i\\right)\\left(x-a\\right)\\right]^{1-\\gamma}\\right\\} ,\n\\]\ndefinimos \\[\nq\\left(x,a\\right)=a^{1-\\gamma}+\\beta c\\left[\\left(1+i\\right)\\left(x-a\\right)\\right]^{1-\\gamma},\n\\] entonces \\[\n\\partial_{a}q=\\left(1-\\gamma\\right)a^{-\\gamma}+\\beta c\\left(1-\\gamma\\right)\\left(1+i\\right)^{1-\\gamma}\\left(-1\\right)\\left(x-a\\right)^{-\\gamma}.\n\\]\nSi \\(\\partial_{a}q=0\\). Entonces\n\\[\\begin{align*}\na^{-\\gamma} & =\\beta c\\left(1+i\\right)^{1-\\gamma}\\left(x-a\\right)^{-\\gamma}\\\\\n\\left(\\beta c\\left(1+i\\right)^{1-\\gamma}\\right)^{-1} & =\\left(\\dfrac{x-a}{a}\\right)^{-\\gamma}\\\\\n\\beta^{-1}c^{-1}\\left(1+i\\right)^{\\gamma-1} & =\\left(\\dfrac{x}{a}-1\\right)^{-\\gamma}\\\\\n\\left[\\beta^{-1}c^{-1}\\left(1+i\\right)^{\\gamma-1}\\right]^{-\\frac{1}{\\gamma}}+1 & =\\dfrac{x}{a}\n\\end{align*}\\]\nPor lo tanto \\[\\begin{align*}\na & =\\dfrac{x}{\\left[\\beta^{-1}c^{-1}\\left(1+i\\right)^{\\gamma-1}\\right]^{-\\frac{1}{\\gamma}}+1}\\\\\n& =\\dfrac{x}{\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1}\n\\end{align*}\\]\nAhora remplazamos en \\(q\\) \\[\\begin{align*}\n\\nu\\left(x\\right) & =\\left(\\dfrac{x}{\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1}\\right)^{1-\\gamma}+\\beta c\\left[\\left(1+i\\right)\\left(x-\\dfrac{x}{\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1}\\right)\\right]^{1-\\gamma}\\\\\n& =x^{1-\\gamma}\\left(\\dfrac{1}{\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1}\\right)+x^{1-\\gamma}\\left(1+i\\right)^{1-\\gamma}\\beta c\\left(1-\\dfrac{1}{\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1}\\right)^{1-\\gamma}\\\\\n& =x^{1-\\gamma}\\left[\\left(\\dfrac{1}{\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1}\\right)+\\left(1+i\\right)^{1-\\gamma}\\beta c\\left(1-\\dfrac{1}{\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1}\\right)^{1-\\gamma}\\right].\n\\end{align*}\\] Entonces\n\\[\\begin{align*}\nc & =\\left(\\dfrac{1}{\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1}\\right)^{1-\\gamma}+\\left(1+i\\right)^{1-\\gamma}\\beta c\\left(1-\\dfrac{1}{\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1}\\right)^{1-\\gamma}\\\\\n& =\\left(\\dfrac{1}{\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1}\\right)^{1-\\gamma}+\\left(1+i\\right)^{1-\\gamma}\\beta c\\left(\\dfrac{\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}}{\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1}\\right)^{1-\\gamma}\\\\\n& =\\left(\\dfrac{1}{\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1}\\right)^{1-\\gamma}\\left(1+\\left(1+i\\right)^{1-\\gamma}\\beta c\\left(\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}\\right)^{1-\\gamma}\\right)\\\\\n& =\\left(\\dfrac{1}{\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1}\\right)^{1-\\gamma}\\left(1+\\left(1+i\\right)^{1-\\gamma}\\beta c\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}-1}\\right)\\\\\n& =\\left(\\dfrac{1}{\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1}\\right)^{1-\\gamma}\\left(1+\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}\\right)\\\\\n& =\\left(\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1\\right)^{\\gamma-1}\\left(1+\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}\\right)\\\\\nc & =\\left(\\left[\\beta c\\left(1+i\\right)^{1-\\gamma}\\right]^{\\frac{1}{\\gamma}}+1\\right)^{\\gamma}\n\\end{align*}\\]\nAhora, nos queda despejar \\(c\\). \\[\\begin{align*}\nc^{\\frac{1}{\\gamma}} & =\\beta^{\\frac{1}{\\gamma}}c^{\\frac{1}{\\gamma}}\\left(1+i\\right)^{\\frac{1}{\\gamma}-1}+1\\\\\n1 & =\\beta^{\\frac{1}{\\gamma}}\\left(1+i\\right)^{\\frac{1}{\\gamma}-1}+c^{-\\frac{1}{\\gamma}}\\\\\nc^{-\\frac{1}{\\gamma}} & =1-\\beta^{\\frac{1}{\\gamma}}\\left(1+i\\right)^{\\frac{1}{\\gamma}-1}\\\\\nc & =\\left(1-\\beta^{\\frac{1}{\\gamma}}\\left(1+i\\right)^{\\frac{1}{\\gamma}-1}\\right)^{-\\gamma}\n\\end{align*}\\]\n\n\nExercise 1.6 Let \\(\\{\\xi_k\\}\\) be a dynamics of iid random variables such that \\(E\\left[\\xi\\right] = 0\\) and \\(E\\left[\\xi^2\\right] = d\\). Consider the dynamics \\[\nx_{k+1} = x_k + a_k + \\xi_k, k = 0,1,2,\\ldots,\n\\]\nand the discounted cost \\[\nE\\left[ \\sum \\beta^k \\left(a^2_k + x_k^2\\right)\\right]\n\\]\n\nWrite down the associated Bellman equation.\nConjecture that the solution to the Bellman equation takes the form \\(v(x) = ax^2 + b\\), where \\(a\\) and \\(b\\) are constant.\nDetermine the constants \\(a\\) and \\(b\\).\nConjecture that the solution to the Bellman equation takes the form \\(v(x) = ax^2 + b\\), where \\(a\\) and \\(b\\) are constant. Determine the constants \\(a\\) and \\(b\\).\n\n\n\n\\[\\begin{align*}\n\\nu\\left(x\\right) & =\\max_{a\\in A\\left(x\\right)}\\left\\{ c\\left(x,a\\right)+E\\left[\\nu\\left(f\\left(x,a\\right)\\right)\\right]\\right\\} \\\\\n& =\\max_{a\\in A\\left(x\\right)}\\left\\{ a^{2}+x^{2}+E\\left[\\nu\\left(x+a+\\xi\\right)\\right]\\right\\}\n\\end{align*}\\]\nPara \\(\\nu\\left(x\\right)=ax^{2}+b\\)\n\\[\\begin{align*}\n\\nu\\left(x\\right) & =\\max_{a\\in A\\left(x\\right)}\\left\\{ c\\left(x,a\\right)+\\beta E\\left[\\nu\\left(f\\left(x,a\\right)\\right)\\right]\\right\\} \\\\\n& =\\max_{a\\in A\\left(x\\right)}\\left\\{ A^{2}+x^{2}+\\beta\\left(E\\left[a\\left(f^{2}\\left(x,a\\right)\\right)\\right]+b\\right)\\right\\} \\\\\n& =\\max_{a\\in A\\left(x\\right)}\\left\\{ A^{2}+x^{2}+\\beta\\left(aE\\left[f^{2}\\left(x,a\\right)\\right]+b\\right)\\right\\}\n\\end{align*}\\]\nNotemos que \\[\\begin{align*}\nE\\left[f^{2}\\left(x,A\\right)\\right] & =E\\left[\\left(x+A+\\xi\\right)^{2}\\right]\\\\\n& =E\\left[x^{2}+A^{2}+\\xi^{2}+2xA+2x\\xi+2\\xi A\\right]\\\\\n& =x^{2}+A^{2}+E\\left[\\xi^{2}\\right]+2xA+2xE\\left[\\xi\\right]+2AE\\left[\\xi\\right]\\\\\n& =x^{2}+A^{2}+d+2xA\n\\end{align*}\\]\nEntonces \\[\\begin{align*}\nax^{2}+b & =\\max_{a\\in A\\left(x\\right)}\\left\\{ A^{2}+x^{2}+\\beta\\left[a\\left(x^{2}+A^{2}+d+2xA\\right)+b\\right]\\right\\} \\\\\n& =\\max_{a\\in A\\left(x\\right)}\\left\\{ A^{2}+x^{2}+\\beta a\\left(x^{2}+A^{2}+d+2xA\\right)+\\beta b\\right\\} \\\\\n& =\\max_{a\\in A\\left(x\\right)}\\left\\{ A^{2}+x^{2}+\\beta ax^{2}+\\beta aA^{2}+\\beta ad+2\\beta axA+\\beta b\\right\\} \\\\\n& =\\max_{a\\in A\\left(x\\right)}\\left\\{ A^{2}\\left(\\beta a+1\\right)+2\\beta axA+x^{2}+\\beta ax^{2}+\\beta ad+\\beta b\\right\\}\n\\end{align*}\\]\nDefinimos \\[\nw\\left(x,A\\right)=A^{2}\\left(\\beta a+1\\right)+2\\beta axA+x^{2}+\\beta ax^{2}+\\beta ad+\\beta b,\n\\]\nentonces \\[\n\\partial_{A}w=2A\\left(\\beta a+1\\right)+2\\beta ax.\n\\]\nSi \\(\\partial_{A}w=0\\), entonces \\[\nA=-\\dfrac{\\beta ax}{\\beta a+1}\n\\]\nEntonces \\[\\begin{align*}\n\\nu\\left(x\\right) & =\\left(\\beta ax\\right)^{2}-2\\dfrac{\\left(\\beta ax\\right)^{2}}{\\beta a+1}+x^{2}+\\beta ax^{2}+\\beta ad+\\beta b\\\\\n& =x^{2}\\left(\\left[\\beta a\\right]^{2}-2\\dfrac{\\left(\\beta a\\right)^{2}}{\\beta a+1}+1+\\beta a\\right)+\\beta ad+\\beta b\n\\end{align*}\\]\nEntonces \\[\\begin{align*}\na & =\\left[\\beta a\\right]^{2}-2\\dfrac{\\left(\\beta a\\right)^{2}}{\\beta a+1}+1+\\beta a\\\\\nb & =\\beta ad+\\beta b,\n\\end{align*}\\] de forma rapida\n\\[\nb=\\dfrac{\\beta ad}{1-\\beta},\n\\] entonces queda pendiente calcular \\(a\\)\n\\[\\begin{align*}\na & =\\left[\\beta a\\right]^{2}-2\\dfrac{\\left(\\beta a\\right)^{2}}{\\beta a+1}+1+\\beta a.\\\\\n0 & =\\left(\\beta a\\right)^{2}\\left(1-\\dfrac{2}{\\beta a+1}\\right)+1+\\left(\\beta-1\\right)a\\\\\n& =\\left(\\beta a\\right)^{2}\\left(\\beta a+1-2\\right)+\\beta a+1+\\left(a\\beta-a\\right)\\left(\\beta a+1\\right)\\\\\n& =\\left(\\beta a\\right)^{2}\\left(\\beta a-1\\right)+\\beta a+1+\\left[\\left(a\\beta\\right)^{2}+a\\beta-\\beta a^{2}-a\\right]\\\\\n& =\\left(\\beta a\\right)^{3}+2a\\beta+1-\\beta a^{2}-a\\\\\n& =\\beta^{3}a^{3}-\\beta a^{2}+\\left(2\\beta-1\\right)a+1\n\\end{align*}\\]\nConcluyendo que la constante \\(b\\) depende de \\(a\\) y \\(a\\) es una solución, dependiente de \\(\\beta\\), de la ecuación cúbica que"
  },
  {
    "objectID": "Extra1.html#verificar-la-ecuación-de-bellman-para-el-problema-de-gridworld-de-la-casilla-s-22",
    "href": "Extra1.html#verificar-la-ecuación-de-bellman-para-el-problema-de-gridworld-de-la-casilla-s-22",
    "title": "3  Ejercicio Extra",
    "section": "3.1 Verificar la ecuación de Bellman para el problema de GridWorld de la casilla \\(s = (2,2)\\)",
    "text": "3.1 Verificar la ecuación de Bellman para el problema de GridWorld de la casilla \\(s = (2,2)\\)\nPor la ecuación de Bellman.\n\\[\\begin{align*}\nv_{\\pi}\\left(s\\right) & =E_{\\pi}\\left[G_{t}\\mid S_{t}=s\\right]\\\\\n& =\\sum_{a}\\pi\\left(a\\mid s\\right)\\sum_{s',r}p\\left(s^{'},r\\mid s,a\\right)\\left[r+\\gamma v_{\\pi}\\left(s'\\right)\\right]\n\\end{align*}\\]\nQueremos calcular \\(v_{\\pi}\\left(s_0\\right)\\) donde \\(s_{0}=\\left(2,2\\right)\\) Considerando el \\(\\left(0,0\\right)\\) la esquina superior izquierda. Comenzaremos revisando \\(p\\left(s^{'},r\\mid s,a\\right)\\). Notemos que en Gridword solo son posibles las recompensas \\(\\{-1,0,5,10\\}\\) según la posición actual y la acción \\(a\\). Para nuestro caso, \\(s= s_{0}\\) \\[\np\\left(s',r\\mid s_{0},a\\right)=0,r\\in\\{-1,5,10\\},\\forall a,\\forall s'.\n\\]\nPor lo anterior la ecuación de Bellman queda como sigue \\[\nv_{\\pi}\\left(s\\right)=\\sum_{a}\\pi\\left(a\\mid s\\right)\\sum_{s'}p\\left(s^{'},0\\mid s_{0},a\\right)\\left[\\gamma v_{\\pi}\\left(s'\\right)\\right].\n\\]\nDefinamos la función auxiliar \\[\ng\\left(a\\right)=\\sum_{s'}p\\left(s^{'},0\\mid s_{0},a\\right)\\left[\\gamma v_{\\pi}\\left(s'\\right)\\right].\n\\]\nPara \\(s=s_{0}\\) y \\(a\\) fijo. \\[\ng\\left(a\\right)=\\gamma v_{\\pi}\\left(s'\\right),\n\\]\ndonde \\(s'\\) satisface \\(\\mathcal{P}\\left(s'\\mid s,a\\right)=1\\). Para el ejercicio, \\(v_{\\pi}\\left(s'\\right)\\) estan dadas para \\(s'=\\left(1,2\\right),s'=\\left(2,1\\right),s'=\\left(2,3\\right),s'=\\left(3,2\\right)\\), y estamos suponiendo una distribución uniforme en \\(\\pi\\). Por lo tanto,\n\\[\n\\pi\\left(a\\mid s\\right)=\\dfrac{1}{4},\\forall s.\n\\]\nFinalmente,\n\\[\\begin{align*}\nv_{\\pi}\\left(s\\right) & =\\dfrac{1}{4}\\left(\\gamma\\left(2.3+0.7+0.4-0.4\\right)\\right)\\\\\n& =\\dfrac{3}{4}\\gamma\\approx0.7\n\\end{align*}\\]"
  },
  {
    "objectID": "Proyecto.html#introducción",
    "href": "Proyecto.html#introducción",
    "title": "4  Proyecto: Manejo de Inventario",
    "section": "4.1 Introducción",
    "text": "4.1 Introducción\nDentro del area del Control Estocástico, una de los problemas más conocidos son los problemas de inventario. Donde se presenta una bodega con capacidad máxima \\(K\\). Cada estapa se extrae una cantidad de mercancía, la que denotaremos como la demanda \\(D_t\\), y se solicita una cantidad del producto \\(a_t\\), obteniendo finalmente el nivel de inventario \\(X_t\\). En general se busca minimizar los costos de la bodega (costos por almacenamiento, costos por pérdida, entre otros)."
  },
  {
    "objectID": "Proyecto.html#formulación-del-proceso-de-decisión-de-markov.",
    "href": "Proyecto.html#formulación-del-proceso-de-decisión-de-markov.",
    "title": "4  Proyecto: Manejo de Inventario",
    "section": "4.2 Formulación del Proceso de Decisión de Markov.",
    "text": "4.2 Formulación del Proceso de Decisión de Markov.\nPara nuestro problema consideraremos un supermercado, centrado en uno de sus pasillos. Suponiendo que en un pasillo se almacena un solo tipo de producto. Definiremos a \\(K\\) la cantidad máxima de producto en el pasillo, \\(X_t\\) a la cantidad del producto disponible para la venta (o la cantidad de producto en el pasillo). Nuestra demanda, o producto solicitado, será denotado por \\(D_t\\) y se considerará una colección de v.a i.i.d. Finalmente, la cantidad recolocada en el pasillo, o producto pedido, será denotada por \\(a_t\\). Entonces, nuestro conjunto de estados \\(\\mathcal{S}\\) está dado por el siguiente conjunto\n\\[\n    \\mathcal{S} = \\{s\\in \\mathbb{Z}^+:0\\leq s\\leq K\\}.\n\\tag{4.1}\\]\nNuestro conjunto de acciones \\(\\mathcal{A} = \\mathcal{S} = \\mathbb{Z}^+\\), y para \\(x\\in\\mathcal{S}\\) nuestro conjunto de acciones admisibles esta dado por\n\\[\n    \\mathcal{A}(x)=\\{a\\in \\mathcal{A}:0 \\leq a\\leq K - x\\}.\n\\]"
  },
  {
    "objectID": "Proyecto.html#dinámica-del-modelo.",
    "href": "Proyecto.html#dinámica-del-modelo.",
    "title": "4  Proyecto: Manejo de Inventario",
    "section": "4.3 Dinámica del Modelo.",
    "text": "4.3 Dinámica del Modelo.\nRecordando la fórmula para nuestro modelo.\n\\[\n    X_{t+1} = f(X_t, a_t), f:\\mathcal{S}\\times \\mathcal{A}\\to \\mathcal{S}.\n\\]\nEntonces el modelo que usaremos esta dado por\n\\[\n    X_{t+1} = (X_t+a_t-\\eta X_{t} - D_{t+1})^+,\n\\tag{4.2}\\]\ndonde \\(a_t\\) es la cantidad de producto recolodado al final del dia \\(t\\), \\(\\eta\\) es el factor descomposición, \\(D_t\\) es la demanda del prodcucto en la dia \\(t\\) y \\((\\cdot)^+ = \\max\\{\\cdot, 0\\}\\)."
  },
  {
    "objectID": "Proyecto.html#descripción-y-justificación-del-modelo.",
    "href": "Proyecto.html#descripción-y-justificación-del-modelo.",
    "title": "4  Proyecto: Manejo de Inventario",
    "section": "4.4 Descripción y Justificación del Modelo.",
    "text": "4.4 Descripción y Justificación del Modelo.\nEl modelo Equation 4.2 pretende responder a la pregunta que denota el modelo ¿Cuánto producto tendré disponible al dia siguiente?. Lo anterior menciona que nuestras etapas \\(t\\in \\mathcal{T} = \\{t\\in \\mathbb{Z}^+: t\\leq T,T\\in \\mathbb{N}\\}\\) representaran los dias dentro de un periodo \\(T\\), \\(t\\) hace referencia al dia actual, y \\(t+1\\) al dia siguiente. Entonces el modelo general esta dado por\n\\[\n    X_{t+1} = (\\text{Today} + \\text{In}_t - \\text{Out}_{t+1})^+.\n\\]\nEsto es, la parte positiva del producto que hay “hoy”, es decir, \\(X_t\\). A eso le agregaremos el producto que entrará hoy al final del dia, en nuestro modelo solo habrá ingreso de producto mediante solicitud (En este caso no consideramos un almacenimiento dentro del supermercado), entonces \\(\\text{In}_t\\) esta dado por nuestras acciones \\(\\text{In}_t = a_t\\).\nLa parte que saldrá consta de dos elementos. En general consideramos la cantidad de producto que se compró en el dia \\(t\\). Sin embargo, desconocemos la cantidad requerida, haciendo referencia al dia siguiente. Por lo tanto la demanda está representada por \\(D_{t+1}\\), la cantidad de producto requerida al dia siguiente. En nuestro modelo también consideramos la salida de producto por considerarse producto no apto para la venta. Entonces\n\\[\n    \\text{Out}_t = D_{t + 1} + N_t(X_t).\n\\]\nBajo de la suposición que todos los productos poseen el mismo tiempo de vida con periodos de vida distintos supondremos que cada dia, al final, se retira un factor con respecto a la cantidad actual de producto. \\[\n    N_t = \\eta X_t\n\\]\n\\[\n    \\text{Out}_t = D_{t + 1} + \\eta X_t\n\\]\nFinalmente, nos queda definir la función de costo, en nuestro modelo será la ganancia. Al considerar un periodo finito tenemos que la ganancia total \\(G\\) esta dada por\n\\[\n    G(x_0, \\pi) = \\sum_{t=0}^{T} G_t(X_t, a_t),X_0 = x_0, X_{t+1} = f(X_t, a_t).\n\\]\ndonde \\(\\pi\\) es una politica, \\(\\pi = (a_0,a_1, \\ldots, a_{N-1})\\). y \\(G_t\\) es la ganancia por etapa, en nuestro caso \\[\n    G_t(x,a) = P_V \\min\\{x + a, D_t\\} - P_S (a - \\mathcal{I}_{t = 0}x),\n\\]\nnotemos que en el dia \\(a = 0\\) y \\(D_0 = 0\\), entonces \\(G_0(x,a) = -P_Sx\\) donde \\(C\\) es el costo unitario por tener el producto al inicio. Notemos que \\(D_t\\) es una variable aleatoria, entonces la función de valor por estado es la siguiente\n\\[\n    V^\\pi(s) =  E[G(s, \\pi)]\n\\]\nTeniendo que la ecuación de Bellman para nuestra función de valor es \\[\n    V^\\pi(s) = \\sum_{a}\\pi(a\\mid s)\\sum_{s'} \\mathcal{P}[s' \\mid s, a][R(s', a, s) + \\gamma V^\\pi(s')]\n\\]"
  },
  {
    "objectID": "Proyecto.html#justificación-de-las-acciones.",
    "href": "Proyecto.html#justificación-de-las-acciones.",
    "title": "4  Proyecto: Manejo de Inventario",
    "section": "4.5 Justificación de las acciones.",
    "text": "4.5 Justificación de las acciones.\nYa comentamos que nuestras acciones, será la cantidad de producto que vamos a solicitar. Entonces nuestras acciones serán números enteros y las acciones serán ejecutadas de forma instantea, al momento."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Ayers, G. 2005. “Air Pollution and Climate Change: Has Air\nPollution Suppressed Rainfall over Australia?” 39 (2): 51–57. https://search.informit.org/doi/10.3316/informit.632702153657460.\n\n\nB. Thomas Jr, George. 2010. Cálculo Varias Variables. Doceava.\nAddison-Wesley."
  }
]